[{"role": "user", "content": "I want to add a dataloader in this so i can make use of pin_memory = True\n\nfrom omegaconf import DictConfig, OmegaConf\nimport os\nfrom tqdm.auto import tqdm\n\nimport json, random\nfrom data.blender import BlenderDataset\nfrom data.google_scanned import GoogleScannedPreprocessed\nfrom data.llff import LLFFDataset\nfrom model.extractor.tensorf import TensorVMSplit\nfrom model.renderer.tensorf import TensoRFRenderer\nfrom tensorboardX import SummaryWriter\nimport datetime\nimport sys\nimport imageio\nimport torch\nfrom .tensorf_utils import *\n\nfrom prettytable import PrettyTable\n\ndef count_parameters(model, file_path=None):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad:\n            continue\n        params = parameter.numel()\n        table.add_row([name, params])\n        total_params += params\n    table.add_row([\"Total Trainable Params\", total_params])\n\n    print(table)\n\n    if file_path:\n        with open(file_path, 'a') as f:\n            f.write(str(table) + \"\\n\")\n            f.write(f\"Total Trainable Params: {total_params}\\n\\n\")\n\n    return total_params\n\nclass SimpleSampler:\n    def __init__(self, total, batch):\n        if batch is None:\n            raise ValueError(\"Batch size must be provided\")\n        self.total = total\n        self.batch = batch\n        self.curr = total\n        self.ids = None\n\n    def nextids(self):\n        self.curr += self.batch\n        if self.curr + self.batch > self.total:\n            self.ids = torch.LongTensor(np.random.permutation(self.total))\n            self.curr = 0\n        return self.ids[self.curr:self.curr+self.batch]\n\n\n@torch.no_grad()\ndef evaluation(test_dataset,tensorf, args, renderer, savePath=None, N_vis=5, prtx='', N_samples=-1,\n               white_bg=False, ndc_ray=False, compute_extra_metrics=True, device='cuda'):\n    PSNRs, rgb_maps, depth_maps = [], [], []\n    ssims,l_alex,l_vgg=[],[],[]\n    os.makedirs(savePath, exist_ok=True)\n    os.makedirs(savePath+\"/rgbd\", exist_ok=True)\n\n    try:\n        tqdm._instances.clear()\n    except Exception:\n        pass\n\n    near_far = test_dataset.near_far\n    img_eval_interval = 1 if N_vis < 0 else max(test_dataset.all_rays.shape[0] // N_vis,1)\n    idxs = list(range(0, test_dataset.all_rays.shape[0], img_eval_interval))\n    for idx, samples in tqdm(enumerate(test_dataset.all_rays[0::img_eval_interval]), file=sys.stdout):\n\n        W, H = test_dataset.img_wh\n        rays = samples.view(-1,samples.shape[-1])\n\n        rgb_map, _, depth_map, _, _ = renderer(rays, tensorf, chunk=4096, N_samples=N_samples,\n                                        ndc_ray=ndc_ray, white_bg = white_bg, device=device)\n        rgb_map = rgb_map.clamp(0.0, 1.0)\n\n        rgb_map, depth_map = rgb_map.reshape(H, W, 3).cpu(), depth_map.reshape(H, W).cpu()\n\n        depth_map, _ = visualize_depth_numpy(depth_map.numpy(),near_far)\n        if len(test_dataset.all_rgbs):\n            gt_rgb = test_dataset.all_rgbs[idxs[idx]].view(H, W, 3)\n            loss = torch.mean((rgb_map - gt_rgb) ** 2)\n            PSNRs.append(-10.0 * np.log(loss.item()) / np.log(10.0))\n\n            if compute_extra_metrics:\n                ssim = rgb_ssim(rgb_map, gt_rgb, 1)\n                l_a = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'alex', tensorf.device)\n                l_v = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'vgg', tensorf.device)\n                ssims.append(ssim)\n                l_alex.append(l_a)\n                l_vgg.append(l_v)\n\n        rgb_map = (rgb_map.numpy() * 255).astype('uint8')\n        # rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n        rgb_maps.append(rgb_map)\n        depth_maps.append(depth_map)\n        if savePath is not None:\n            imageio.imwrite(f'{savePath}/{prtx}{idx:03d}.png', rgb_map)\n            rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n            imageio.imwrite(f'{savePath}/rgbd/{prtx}{idx:03d}.png', rgb_map)\n\n    imageio.mimwrite(f'{savePath}/{prtx}video.mp4', np.stack(rgb_maps), fps=30, quality=10)\n    imageio.mimwrite(f'{savePath}/{prtx}depthvideo.mp4', np.stack(depth_maps), fps=30, quality=10)\n\n    if PSNRs:\n        psnr = np.mean(np.asarray(PSNRs))\n        if compute_extra_metrics:\n            ssim = np.mean(np.asarray(ssims))\n            l_a = np.mean(np.asarray(l_alex))\n            l_v = np.mean(np.asarray(l_vgg))\n            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr, ssim, l_a, l_v]))\n        else:\n            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr]))\n    return PSNRs\n\n\nclass TensoRFGoogleScannedTrainer:\n    def __init__(self, args: DictConfig):\n        super().__init__()\n        self.args = args\n        self.device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n        self.renderer = TensoRFRenderer()\n\n        if args.add_timestamp:\n            self.logfolder = f'{args.basedir}/{args.expname}{datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")}'\n        else:\n            self.logfolder = f'{args.basedir}/{args.expname}'\n\n        os.makedirs(self.logfolder, exist_ok=True)\n        self.model_log_file = os.path.join(self.logfolder, 'model_parameters.txt')\n\n    def save_model_details(self, model, description):\n        with open(self.model_log_file, 'a') as f:\n            f.write(f\"== {description} ==\\n\")\n            # Save necessary model details\n            f.write(f\"AABB: {model.aabb}\\n\")\n            # Add more model details as needed\n            f.write(\"\\n\")\n        count_parameters(model, self.model_log_file)\n\n    def train(self):\n        args = self.args\n        device = self.device\n        renderer = self.renderer\n\n        # init dataset\n        train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=False)\n        test_dataset = eval(args.data_loader)(args.datadir, split='test', downsample=args.downsample_train, is_stack=True)\n        white_bg = train_dataset.white_bg\n        near_far = train_dataset.near_far\n        ndc_ray = args.ndc_ray\n\n        # init resolution\n        upsamp_list = args.upsamp_list\n        update_AlphaMask_list = args.update_AlphaMask_list\n        n_lamb_sigma = args.n_lamb_sigma\n        n_lamb_sh = args.n_lamb_sh\n\n        summary_writer = SummaryWriter(self.logfolder)\n\n        # init parameters\n        aabb = train_dataset.scene_bbox.to(device)\n        reso_cur = N_to_reso(args.N_voxel_init, aabb)\n        nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n\n        if args.ckpt is not None and os.path.exists(args.ckpt):\n            ckpt = torch.load(args.ckpt, map_location=device)\n            kwargs = ckpt['kwargs']\n            kwargs.update({'device': device})\n            tensorf = eval(args.model_name)(**kwargs)\n            tensorf.load(ckpt)\n        else:\n            tensorf = eval(args.model_name)(aabb, reso_cur, device,\n                                            density_n_comp=n_lamb_sigma, appearance_n_comp=n_lamb_sh,\n                                            density_pick_plane=args.density_pick_plane, app_pick_plane=args.app_pick_plane,\n                                            app_dim=args.data_dim_color, near_far=near_far,\n                                            shadingMode=args.shadingMode, alphaMask_thres=args.alpha_mask_thre,\n                                            density_shift=args.density_shift, distance_scale=args.distance_scale,\n                                            pos_pe=args.pos_pe, view_pe=args.view_pe, fea_pe=args.fea_pe,\n                                            featureC=args.featureC, step_ratio=args.step_ratio,\n                                            fea2denseAct=args.fea2denseAct)\n\n        # Save model details at initialization\n        self.save_model_details(tensorf, 'Model Initialization')\n\n        grad_vars = tensorf.get_optparam_groups(args.lr_init, args.lr_basis)\n        if args.lr_decay_iters > 0:\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.lr_decay_iters)\n        else:\n            args.lr_decay_iters = args.n_iters\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.n_iters)\n\n        print(\"lr decay\", args.lr_decay_target_ratio, args.lr_decay_iters)\n\n        optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n        # linear in log space\n        N_voxel_list = (torch.round(torch.exp(torch.linspace(np.log(args.N_voxel_init), np.log(args.N_voxel_final),\n                                                             len(upsamp_list) + 1))).long()).tolist()[1:]\n\n        torch.cuda.empty_cache()\n        PSNRs, PSNRs_test = [], [0]\n\n        allrays, allrgbs = train_dataset.all_rays, train_dataset.all_rgbs\n        if not args.ndc_ray:\n            allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs, bbox_only=True)\n        trainingSampler = SimpleSampler(allrays.shape[0], args.batch_size)\n\n        Ortho_reg_weight = args.Ortho_weight\n        print(\"initial Ortho_reg_weight\", Ortho_reg_weight)\n\n        L1_reg_weight = args.L1_weight_inital\n        print(\"initial L1_reg_weight\", L1_reg_weight)\n        TV_weight_density, TV_weight_app = args.TV_weight_density, args.TV_weight_app\n        tvreg = TVLoss()\n        print(f\"initial TV_weight density: {TV_weight_density} appearance: {TV_weight_app}\")\n\n        pbar = tqdm(range(args.n_iters), miniters=args.progress_refresh_rate, file=sys.stdout)\n        for _ in pbar:\n\n            iteration = tensorf.iteration\n\n            ray_idx = trainingSampler.nextids()\n            rays_train, rgb_train = allrays[ray_idx], allrgbs[ray_idx].to(device)\n\n            # rgb_map, alphas_map, depth_map, weights, uncertainty\n            rgb_map, alphas_map, depth_map, weights, uncertainty = renderer(rays_train, tensorf,\n                                                                            chunk=args.batch_size,\n                                                                            N_samples=nSamples, white_bg=white_bg,\n                                                                            ndc_ray=ndc_ray, device=device,\n                                                                            is_train=True)\n\n            loss = torch.mean((rgb_map - rgb_train) ** 2)\n\n            # loss\n            total_loss = loss\n            if Ortho_reg_weight > 0:\n                loss_reg = tensorf.vector_comp_diffs()\n                total_loss += Ortho_reg_weight * loss_reg\n                summary_writer.add_scalar('train/reg', loss_reg.detach().item(), global_step=iteration)\n            if L1_reg_weight > 0:\n                loss_reg_L1 = tensorf.density_L1()\n                total_loss += L1_reg_weight * loss_reg_L1\n                summary_writer.add_scalar('train/reg_l1', loss_reg_L1.detach().item(), global_step=iteration)\n\n            if TV_weight_density > 0:\n                TV_weight_density *= lr_factor\n                loss_tv = tensorf.TV_loss_density(tvreg) * TV_weight_density\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_density', loss_tv.detach().item(), global_step=iteration)\n            if TV_weight_app > 0:\n                TV_weight_app *= lr_factor\n                loss_tv = tensorf.TV_loss_app(tvreg) * TV_weight_app\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_app', loss_tv.detach().item(), global_step=iteration)\n\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n\n            loss = loss.detach().item()\n\n            PSNRs.append(-10.0 * np.log(loss) / np.log(10.0))\n            summary_writer.add_scalar('train/PSNR', PSNRs[-1], global_step=iteration)\n            summary_writer.add_scalar('train/mse', loss, global_step=iteration)\n\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = param_group['lr'] * lr_factor\n\n\n            if iteration % args.vis_every == args.vis_every - 1 and args.N_vis != 0:\n                PSNRs_test = evaluation(test_dataset, tensorf, args, renderer, f'{self.logfolder}/imgs_vis/',\n                                        N_vis=args.N_vis,\n                                        prtx=f'{iteration:06d}_', N_samples=nSamples, white_bg=white_bg,\n                                        ndc_ray=ndc_ray, compute_extra_metrics=False)\n                summary_writer.add_scalar('test/psnr', np.mean(PSNRs_test), global_step=iteration)\n\n            # Print the current values of the losses.\n            if iteration % args.progress_refresh_rate == 0 or iteration == args.n_iters - 1:\n                pbar.set_description(\n                    f'Iteration {iteration:05d}:'\n                    + f' train_psnr = {float(np.mean(PSNRs)):.2f}'\n                    + f' test_psnr = {float(np.mean(PSNRs_test)):.2f}'\n                    + f' mse = {loss:.6f}'\n                )\n                PSNRs = []\n\n            if iteration in update_AlphaMask_list:\n\n                if reso_cur[0] * reso_cur[1] * reso_cur[2] < args:  # update volume resolution\n                    reso_mask = reso_cur\n                new_aabb = tensorf.updateAlphaMask(tuple(reso_mask))\n                if iteration == update_AlphaMask_list[0]:\n                    tensorf.shrink(new_aabb)\n                    # tensorVM.alphaMask = None\n                    L1_reg_weight = args.L1_weight_rest\n                    print(\"continuing L1_reg_weight\", L1_reg_weight)\n\n                if not args.ndc_ray and iteration == update_AlphaMask_list[1]:\n                    # filter rays outside the bbox\n                    allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs)\n                    trainingSampler = SimpleSampler(allrgbs.shape[0], args.batch_size)\n\n            if iteration in upsamp_list:\n                n_voxels = N_voxel_list.pop(0)\n                reso_cur = N_to_reso(n_voxels, tensorf.aabb)\n                nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n                tensorf.upsample_volume_grid(reso_cur)\n\n                # Save model details during upsampling\n                self.save_model_details(tensorf, 'Model Upsampling')\n\n                if args.lr_upsample_reset:\n                    print(\"reset lr to initial\")\n                    lr_scale = 1  # 0.1 ** (iteration / args.n_iters)\n                else:\n                    lr_scale = args.lr_decay_target_ratio ** (iteration / args.n_iters)\n                grad_vars = tensorf.get_optparam_groups(args.lr_init * lr_scale, args.lr_basis * lr_scale)\n                optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n            tensorf.iteration += 1\n\n        if args.render_train:\n            os.makedirs(f'{self.logfolder}/imgs_train_all', exist_ok=True)\n            train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=True)\n            PSNRs_test = evaluation(train_dataset,tensorf, args, renderer, f'{self.logfolder}/imgs_train_all/',\n                                    N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device)\n            print(f'======> {args.expname} TRAIN all psnr: {np.mean(PSNRs_test)} <========================')\n\n        return\n"}, {"role": "assistant", "content": "To incorporate a DataLoader that makes use of `pin_memory=True`, you'll need to organize your data handling into batches and use PyTorch's `DataLoader` class. Here\u2019s how you can modify your code to use a PyTorch `DataLoader` for the `train_dataset` and enable `pin_memory`.\n\nFirst, let's modify the `train` method in your `TensoRFGoogleScannedTrainer` class to use PyTorch's `DataLoader`:\n\n```python\nimport torch.utils.data\nfrom torch.utils.data import DataLoader, Dataset\n\nclass RaysDataset(Dataset):\n    def __init__(self, rays, rgbs):\n        super().__init__()\n        self.rays = rays\n        self.rgbs = rgbs\n\n    def __len__(self):\n        return self.rays.shape[0]\n\n    def __getitem__(self, idx):\n        return self.rays[idx], self.rgbs[idx]\n\nclass TensoRFGoogleScannedTrainer:\n    # ...other methods...\n\n    def train(self):\n        args = self.args\n        device = self.device\n        renderer = self.renderer\n\n        # init dataset\n        train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=False)\n        test_dataset = eval(args.data_loader)(args.datadir, split='test', downsample=args.downsample_train, is_stack=True)\n        white_bg = train_dataset.white_bg\n        near_far = train_dataset.near_far\n        ndc_ray = args.ndc_ray\n\n        # Creating PyTorch DataLoader\n        allrays, allrgbs = train_dataset.all_rays, train_dataset.all_rgbs\n        if not args.ndc_ray:\n            allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs, bbox_only=True)\n\n        train_ray_rgb_dataset = RaysDataset(allrays, allrgbs)\n        train_dataloader = DataLoader(train_ray_rgb_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True)\n\n        # init resolution\n        upsamp_list = args.upsamp_list\n        update_AlphaMask_list = args.update_AlphaMask_list\n        n_lamb_sigma = args.n_lamb_sigma\n        n_lamb_sh = args.n_lamb_sh\n\n        summary_writer = SummaryWriter(self.logfolder)\n\n        # init parameters\n        aabb = train_dataset.scene_bbox.to(device)\n        reso_cur = N_to_reso(args.N_voxel_init, aabb)\n        nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n\n        if args.ckpt is not None and os.path.exists(args.ckpt):\n            ckpt = torch.load(args.ckpt, map_location=device)\n            kwargs = ckpt['kwargs']\n            kwargs.update({'device': device})\n            tensorf = eval(args.model_name)(**kwargs)\n            tensorf.load(ckpt)\n        else:\n            tensorf = eval(args.model_name)(aabb, reso_cur, device,\n                                            density_n_comp=n_lamb_sigma, appearance_n_comp=n_lamb_sh,\n                                            density_pick_plane=args.density_pick_plane, app_pick_plane=args.app_pick_plane,\n                                            app_dim=args.data_dim_color, near_far=near_far,\n                                            shadingMode=args.shadingMode, alphaMask_thres=args.alpha_mask_thre,\n                                            density_shift=args.density_shift, distance_scale=args.distance_scale,\n                                            pos_pe=args.pos_pe, view_pe=args.view_pe, fea_pe=args.fea_pe,\n                                            featureC=args.featureC, step_ratio=args.step_ratio,\n                                            fea2denseAct=args.fea2denseAct)\n\n        # Save model details at initialization\n        self.save_model_details(tensorf, 'Model Initialization')\n\n        grad_vars = tensorf.get_optparam_groups(args.lr_init, args.lr_basis)\n        if args.lr_decay_iters > 0:\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.lr_decay_iters)\n        else:\n            args.lr_decay_iters = args.n_iters\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.n_iters)\n\n        print(\"lr decay\", args.lr_decay_target_ratio, args.lr_decay_iters)\n\n        optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n        # linear in log space\n        N_voxel_list = (torch.round(torch.exp(torch.linspace(np.log(args.N_voxel_init), np.log(args.N_voxel_final),\n                                                             len(upsamp_list) + 1))).long()).tolist()[1:]\n\n        torch.cuda.empty_cache()\n        PSNRs, PSNRs_test = [], [0]\n\n        Ortho_reg_weight = args.Ortho_weight\n        print(\"initial Ortho_reg_weight\", Ortho_reg_weight)\n\n        L1_reg_weight = args.L1_weight_inital\n        print(\"initial L1_reg_weight\", L1_reg_weight)\n        TV_weight_density, TV_weight_app = args.TV_weight_density, args.TV_weight_app\n        tvreg = TVLoss()\n        print(f\"initial TV_weight density: {TV_weight_density} appearance: {TV_weight_app}\")\n\n        pbar = tqdm(range(args.n_iters), miniters=args.progress_refresh_rate, file=sys.stdout)\n        for _ in pbar:\n            iteration = tensorf.iteration\n\n            for rays_train, rgb_train in train_dataloader:\n                rays_train = rays_train.to(device)\n                rgb_train = rgb_train.to(device)\n\n                # rgb_map, alphas_map, depth_map, weights, uncertainty\n                rgb_map, alphas_map, depth_map, weights, uncertainty = renderer(rays_train, tensorf,\n                                                                                chunk=args.batch_size,\n                                                                                N_samples=nSamples, white_bg=white_bg,\n                                                                                ndc_ray=ndc_ray, device=device,\n                                                                                is_train=True)\n\n                loss = torch.mean((rgb_map - rgb_train) ** 2)\n\n                # loss\n                total_loss = loss\n                if Ortho_reg_weight > 0:\n                    loss_reg = tensorf.vector_comp_diffs()\n                    total_loss += Ortho_reg_weight * loss_reg\n                    summary_writer.add_scalar('train/reg', loss_reg.detach().item(), global_step=iteration)\n                if L1_reg_weight > 0:\n                    loss_reg_L1 = tensorf.density_L1()\n                    total_loss += L1_reg_weight * loss_reg_L1\n                    summary_writer.add_scalar('train/reg_l1', loss_reg_L1.detach().item(), global_step=iteration)\n\n                if TV_weight_density > 0:\n                    TV_weight_density *= lr_factor\n                    loss_tv = tensorf.TV_loss_density(tvreg) * TV_weight_density\n                    total_loss = total_loss + loss_tv\n                    summary_writer.add_scalar('train/reg_tv_density', loss_tv.detach().item(), global_step=iteration)\n                if TV_weight_app > 0:\n                    TV_weight_app *= lr_factor\n                    loss_tv = tensorf.TV_loss_app(tvreg) * TV_weight_app\n                    total_loss = total_loss + loss_tv\n                    summary_writer.add_scalar('train/reg_tv_app', loss_tv.detach().item(), global_step=iteration)\n\n                optimizer.zero_grad()\n                total_loss.backward()\n                optimizer.step()\n\n                loss = loss.detach().item()\n\n                PSNRs.append(-10.0 * np.log(loss) / np.log(10.0))\n                summary_writer.add_scalar('train/PSNR', PSNRs[-1], global_step=iteration)\n                summary_writer.add_scalar('train/mse', loss, global_step=iteration)\n\n                for param_group in optimizer.param_groups:\n                    param_group['lr'] = param_group['lr'] * lr_factor\n\n            if iteration % args.vis_every == args.vis_every - 1 and args.N_vis != 0:\n                PSNRs_test = evaluation(test_dataset, tensorf, args, renderer, f'{self.logfolder}/imgs_vis/',\n                                        N_vis=args.N_vis,\n                                        prtx=f'{iteration:06d}_', N_samples=nSamples, white_bg=white_bg,\n                                        ndc_ray=ndc_ray, compute_extra_metrics=False)\n                summary_writer.add_scalar('test/psnr', np.mean(PSNRs_test), global_step=iteration)\n\n            # Print the current values of the losses.\n            if iteration % args.progress_refresh_rate == 0 or iteration == args.n_iters - 1:\n                pbar.set_description(\n                    f'Iteration {iteration:05d}:'\n                    + f' train_psnr = {float(np.mean(PSNRs)):.2f}'\n                    + f' test_psnr = {float(np.mean(PSNRs_test)):.2f}'\n                    + f' mse = {loss:.6f}'\n                )\n                PSNRs = []\n\n            if iteration in update_AlphaMask_list:\n                if reso_cur[0] * reso_cur[1] * reso_cur[2] < args:  # update volume resolution\n                    reso_mask = reso_cur\n                new_aabb = tensorf.updateAlphaMask(tuple(reso_mask))\n                if iteration == update_AlphaMask_list[0]:\n                    tensorf.shrink(new_aabb)\n                    # tensorVM.alphaMask = None\n                    L1_reg_weight = args.L1_weight_rest\n                    print(\"continuing L1_reg_weight\", L1_reg_weight)\n\n                if not args.ndc_ray and iteration == update_AlphaMask_list[1]:\n                    # filter rays outside the bbox\n                    allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs)\n                    train_ray_rgb_dataset = RaysDataset(allrays, allrgbs)\n                    train_dataloader = DataLoader(train_ray_rgb_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True)\n\n            if iteration in upsamp_list:\n                n_voxels = N_voxel_list.pop(0)\n                reso_cur = N_to_reso(n_voxels, tensorf.aabb)\n                nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n                tensorf.upsample_volume_grid(reso_cur)\n\n                # Save model details during upsampling\n                self.save_model_details(tensorf, 'Model Upsampling')\n\n                if args.lr_upsample_reset:\n                    print(\"reset lr to initial\")\n                    lr_scale = 1  # 0.1 ** (iteration / args.n_iters)\n                else:\n                    lr_scale = args.lr_decay_target_ratio ** (iteration / args.n_iters)\n                grad_vars = tensorf.get_optparam_groups(args.lr_init * lr_scale, args.lr_basis * lr_scale)\n                optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n            tensorf.iteration += 1\n\n        if args.render_train:\n            os.makedirs(f'{self.logfolder}/imgs_train_all', exist_ok=True)\n            train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=True)\n            PSNRs_test = evaluation(train_dataset, tensorf, args, renderer, f'{self.logfolder}/imgs_train_all/',\n                                    N_vis=-1, N_samples=-1, white_bg=white_bg, ndc_ray=ndc_ray, device=device)\n            print(f'======> {args.expname} TRAIN all psnr: {np.mean(PSNRs_test)} <========================')\n\n        return\n```\n\nHere's a summary of the changes:\n\n1. Added a `RaysDataset` class derived from `torch.utils.data.Dataset` to hold rays and RGB values.\n2. Created a `DataLoader` instance `train_dataloader` with `pin_memory=True`.\n3. Replaced the custom sampling logic in the training loop with iterations over `train_dataloader`.\n\nThis setup will ensure efficient data loading and potentially better performance if you have fast enough storage and a large enough dataset that benefits from `pin_memory=True`."}, {"role": "user", "content": "Add the pin memory here\n\nimport torch\nimport cv2\nfrom torch.utils.data import Dataset\nimport json\nfrom tqdm import tqdm\nimport os\nfrom PIL import Image\nfrom torchvision import transforms as T\nimport numpy as np\n\nfrom data.ray_utils import get_ray_directions, get_camera_normals, get_rays_and_norms, read_pfm\n\nclass GoogleScannedPreprocessed(Dataset):\n    def __init__(self, datadir, split='train', downsample=1.0, is_stack=False, N_vis=-1):\n        \"\"\"\n        Initialize the GoogleScannedPreprocessed dataset.\n        \n        Args:\n            datadir (str): Path to the dataset directory.\n            split (str): Dataset split ('train', 'val', 'test').\n            downsample (float): Factor to downsample images.\n            is_stack (bool): Whether to stack rays and rgbs or concatenate them.\n            N_vis (int): Number of images to use for visualization (-1 for all).\n        \"\"\"\n        self.N_vis = N_vis\n        self.root_dir = datadir\n        self.split = split\n        self.is_stack = is_stack\n        self.img_wh = (int(800/downsample), int(800/downsample))\n\n        self.downsample = downsample\n        self.define_transforms()\n\n        self.scene_bbox = torch.tensor([[-2.5, -2.5, -2.5], [2.5, 2.5, 2.5]])  # scene bounding box\n        self.blender2opencv = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n        self.read_meta()\n        self.define_proj_mat()\n\n        self.white_bg = True\n        self.near_far = [0.5, 5.0]\n        \n        self.center = torch.mean(self.scene_bbox, axis=0).float().view(1, 1, 3)\n        self.radius = (self.scene_bbox[1] - self.center).float().view(1, 1, 3)\n\n    def read_depth(self, filename):\n        \"\"\"Read depth data from PFM file.\"\"\"\n        try:\n            depth = np.array(read_pfm(filename)[0], dtype=np.float32)  # (800, 800)\n            return depth\n        except Exception as e:\n            print(f\"Error reading depth file {filename}: {e}\")\n            return None\n    \n    def read_meta(self):\n        \"\"\"Read metadata and process image data.\"\"\"\n        meta_file = os.path.join(self.root_dir, f\"transforms_{self.split}.json\")\n        if not os.path.exists(meta_file):\n            raise FileNotFoundError(f\"Metadata file not found: {meta_file}\")\n\n        with open(meta_file, 'r') as f:\n            self.meta = json.load(f)\n\n        w, h = self.img_wh\n\n        # Assume self.meta['camera_angle_x'] is in degrees\n        angle_x_rad = self.meta['camera_angle_y']\n        # angle_x_deg = np.rad2deg(angle_x_rad)  # Convert degrees to radians\n\n        # Compute the focal length based on the field of view angle in radians\n        self.focal = 0.5 * 800 / np.tan(0.5 * angle_x_rad)  # original focal length\n        self.focal *= self.img_wh[0] / 800  # modify focal length to match size self.img_wh\n        # ray directions for all pixels, same for all images (same H, W, focal)\n        \n        self.directions = get_ray_directions(h, w, [self.focal, self.focal])  # (h, w, 3)\n        self.directions = self.directions / torch.norm(self.directions, dim=-1, keepdim=True)\n        self.intrinsics = torch.tensor([[self.focal, 0, w/2], [0, self.focal, h/2], [0, 0, 1]]).float()\n        \n        self.normals = get_camera_normals(h, w, [self.focal, self.focal])  # (h, w, 3)\n        self.normals = self.normals / torch.norm(self.normals, dim=-1, keepdim=True)\n\n        self.image_paths = []\n        self.poses = []\n        self.all_rays = []\n        self.all_rgbs = []\n        self.all_masks = []\n        self.all_depth = []\n\n        img_eval_interval = 1 if self.N_vis < 0 else max(len(self.meta['frames']) // self.N_vis, 1)\n        idxs = list(range(0, len(self.meta['frames']), img_eval_interval))\n        for i in tqdm(idxs, desc=f'Loading data {self.split} ({len(idxs)})'):\n            frame = self.meta['frames'][i]\n            pose = np.array(frame['transform_matrix']) @ self.blender2opencv\n            c2w = torch.FloatTensor(pose)\n            self.poses.append(c2w)\n\n            image_path = os.path.join(self.root_dir, frame['file_path'])\n            self.image_paths.append(image_path)\n            \n            if not os.path.exists(image_path):\n                raise FileNotFoundError(f\"Image file not found: {image_path}\")\n\n            img = Image.open(image_path)\n            \n            if self.downsample != 1.0:\n                img = img.resize(self.img_wh, Image.LANCZOS)\n            img = self.transform(img)  # (4, h, w)\n            img = img.view(4, -1).permute(1, 0)  # (h*w, 4) RGBA\n            img = img[:, :3] * img[:, -1:] + (1 - img[:, -1:])  # blend A to RGB\n            self.all_rgbs.append(img)\n\n            rays_o, rays_d, rays_n = get_rays_and_norms(self.directions, self.normals, c2w)  # all three (h*w, 3)\n            self.all_rays.append(torch.cat([rays_o, rays_d, rays_n], 1))  # (h*w, 9)\n\n        self.poses = torch.stack(self.poses)\n        if not self.is_stack:\n            self.all_rays = torch.cat(self.all_rays, 0)  # (len(self.meta['frames])*h*w, 9)\n            self.all_rgbs = torch.cat(self.all_rgbs, 0)  # (len(self.meta['frames])*h*w, 3)\n        else:\n            self.all_rays = torch.stack(self.all_rays, 0)  # (len(self.meta['frames']), h*w, 9)\n            self.all_rgbs = torch.stack(self.all_rgbs, 0).reshape(-1, *self.img_wh[::-1], 3)  # (len(self.meta['frames']), h, w, 3)\n\n    def define_transforms(self):\n        \"\"\"Define image transformations.\"\"\"\n        self.transform = T.ToTensor()\n        \n    def define_proj_mat(self):\n        \"\"\"Define projection matrix.\"\"\"\n        # self.proj_mat = self.intrinsics.unsqueeze(0) @ torch.inverse(self.poses)[:, :3]\n        pass\n\n    def world2ndc(self, points, lindisp=None):\n        \"\"\"Convert world coordinates to normalized device coordinates.\"\"\"\n        device = points.device\n        return (points - self.center.to(device)) / self.radius.to(device)\n        \n    def __len__(self):\n        \"\"\"Return the length of the dataset.\"\"\"\n        return len(self.all_rgbs)\n\n    def __getitem__(self, idx):\n        \"\"\"Retrieve a sample from the dataset.\"\"\"\n        if self.split == 'train':  # use data in the buffers\n            sample = {'rays': self.all_rays[idx], 'rgbs': self.all_rgbs[idx]}\n        else:  # create data for each image separately\n            img = self.all_rgbs[idx]\n            rays = self.all_rays[idx]\n            sample = {'rays': rays, 'rgbs': img}\n            if hasattr(self, 'all_masks') and len(self.all_masks) > idx:\n                sample['mask'] = self.all_masks[idx]  # for quantity evaluation\n        return sample\n\n\nif __name__ == '__main__':\n    dataset = GoogleScannedPreprocessed('/project/jacobcha/nk643/neural_point_render/extras/shark_render', split='train', downsample=1.0, is_stack=False, N_vis=-1)\n    print(f\"Dataset length: {len(dataset)}\")\n    print(f\"All rays shape: {dataset.all_rays.shape}\")\n    print(f\"All RGBs shape: {dataset.all_rgbs.shape}\")\n    \n    sample = dataset[0]\n    print(f\"Sample rays shape: {sample['rays'].shape}\")\n    print(f\"Sample RGBs shape: {sample['rgbs'].shape}\")\n\n    \n"}, {"role": "assistant", "content": "To add the `pin_memory` functionality, you mainly need to adjust the DataLoader instantiation. The `pin_memory` parameter comes into play when creating DataLoader instances, which tells PyTorch to pre-fetch data into page-locked memory, which speeds up the transfer of data to CUDA-enabled GPUs.\n\nHere's how you can modify the main part of the script to include `pin_memory` when you create a DataLoader:\n\n```python\nfrom torch.utils.data import DataLoader\n\nif __name__ == '__main__':\n    # Adjust the parameters based on your requirements\n    dataset = GoogleScannedPreprocessed('/project/jacobcha/nk643/neural_point_render/extras/shark_render', split='train', downsample=1.0, is_stack=False, N_vis=-1)\n    print(f\"Dataset length: {len(dataset)}\")\n    print(f\"All rays shape: {dataset.all_rays.shape}\")\n    print(f\"All RGBs shape: {dataset.all_rgbs.shape}\")\n\n    # Create a DataLoader with pin_memory=True\n    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)\n\n    for i, sample in enumerate(dataloader):\n        print(f\"Batch {i} rays shape: {sample['rays'].shape}\")\n        print(f\"Batch {i} RGBs shape: {sample['rgbs'].shape}\")\n```\n\nIn the `DataLoader` instantiation:\n- `batch_size` is set to 4, but you can adjust this based on your memory/dataset size.\n- `shuffle=True` will shuffle the dataset, which is typically done for training.\n- `num_workers=4` configures the number of subprocesses for data loading; adjust it according to your system's capabilities.\n- `pin_memory=True` enables pinning memory, which speeds up data transfer to the GPU.\n\nThis setup will use the `pin_memory` functionality to speed up your training process when moving data to the GPU."}, {"role": "user", "content": "dont i need to call super?\n\n\nclass GoogleScannedPreprocessed(Dataset):\n    def __init__(self, datadir, split='train', downsample=1.0, is_stack=False, N_vis=-1):\n        \"\"\"\n        Initialize the GoogleScannedPreprocessed dataset.\n        \n        Args:\n            datadir (str): Path to the dataset directory.\n            split (str): Dataset split ('train', 'val', 'test').\n            downsample (float): Factor to downsample images.\n            is_stack (bool): Whether to stack rays and rgbs or concatenate them.\n            N_vis (int): Number of images to use for visualization (-1 for all).\n        \"\"\"\n        self.N_vis = N_vis\n        self.root_dir = datadir\n        self.split = split\n        self.is_stack = is_stack\n        self.img_wh = (int(800/downsample), int(800/downsample))\n\n        self.downsample = downsample\n        self.define_transforms"}, {"role": "assistant", "content": "In the context of defining custom classes in Python, especially when dealing with inheritance, it's often necessary to call the `__init__` method of the parent class using `super()`. This ensures that any initialization code present in the parent class is properly executed, maintaining the intended functionality and consistency of the inherited class.\n\nHere, assuming that `Dataset` is an existing class that you are inheriting from (like those provided by popular libraries such as PyTorch), you'll definitely want to call the parent `__init__()` to ensure any setup done by the base class is not skipped.\n\nBelow is your original class definition modified to add the call to `super().__init__()`:\n\n```python\nfrom torch.utils.data import Dataset\n\nclass GoogleScannedPreprocessed(Dataset):\n    def __init__(self, datadir, split='train', downsample=1.0, is_stack=False, N_vis=-1):\n        \"\"\"\n        Initialize the GoogleScannedPreprocessed dataset.\n        \n        Args:\n            datadir (str): Path to the dataset directory.\n            split (str): Dataset split ('train', 'val', 'test').\n            downsample (float): Factor to downsample images.\n            is_stack (bool): Whether to stack rays and rgbs or concatenate them.\n            N_vis (int): Number of images to use for visualization (-1 for all).\n        \"\"\"\n        super().__init__()  # Call the parent class's __init__ method\n        self.N_vis = N_vis\n        self.root_dir = datadir\n        self.split = split\n        self.is_stack = is_stack\n        self.img_wh = (int(800/downsample), int(800/downsample))\n\n        self.downsample = downsample\n        self.define_transforms()\n\n    def define_transforms(self):\n        # Initialize transformation pipeline\n        # (assuming you will define the transformations inside this method)\n        pass\n\n# Additional methods (such as __len__, __getitem__, etc.) would go here.\n```\n\nIn this example, `super().__init__()` ensures that any necessary initialization in `Dataset` is performed. Initializing the parent class in this way is a best practice, particularly when working with libraries such as PyTorch which might have critical setup steps in their `__init__` methods."}, {"role": "user", "content": "Add ML flow tracking\n\nfrom omegaconf import DictConfig, OmegaConf\nimport os\nfrom tqdm.auto import tqdm\n\nimport json, random\nfrom data.blender import BlenderDataset\nfrom data.google_scanned import GoogleScannedPreprocessed\nfrom data.llff import LLFFDataset\nimport torch.utils.data\nfrom torch.utils.data import DataLoader\nfrom model.extractor.tensorf import TensorVMSplit\nfrom model.renderer.tensorf import TensoRFRenderer\nfrom tensorboardX import SummaryWriter\nimport datetime\nimport sys\nimport imageio\nimport torch\nfrom .tensorf_utils import *\n\nfrom prettytable import PrettyTable\n\ndef count_parameters(model, file_path=None):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad:\n            continue\n        params = parameter.numel()\n        table.add_row([name, params])\n        total_params += params\n    table.add_row([\"Total Trainable Params\", total_params])\n\n    print(table)\n\n    if file_path:\n        with open(file_path, 'a') as f:\n            f.write(str(table) + \"\\n\")\n            f.write(f\"Total Trainable Params: {total_params}\\n\\n\")\n\n    return total_params\n\nclass SimpleSampler:\n    def __init__(self, total, batch):\n        if batch is None:\n            raise ValueError(\"Batch size must be provided\")\n        self.total = total\n        self.batch = batch\n        self.curr = total\n        self.ids = None\n\n    def nextids(self):\n        self.curr += self.batch\n        if self.curr + self.batch > self.total:\n            self.ids = torch.LongTensor(np.random.permutation(self.total))\n            self.curr = 0\n        return self.ids[self.curr:self.curr+self.batch]\n\n\n@torch.no_grad()\ndef evaluation(test_dataset,tensorf, args, renderer, savePath=None, N_vis=5, prtx='', N_samples=-1,\n               white_bg=False, ndc_ray=False, compute_extra_metrics=True, device='cuda'):\n    PSNRs, rgb_maps, depth_maps = [], [], []\n    ssims,l_alex,l_vgg=[],[],[]\n    os.makedirs(savePath, exist_ok=True)\n    os.makedirs(savePath+\"/rgbd\", exist_ok=True)\n\n    try:\n        tqdm._instances.clear()\n    except Exception:\n        pass\n\n    near_far = test_dataset.near_far\n    img_eval_interval = 1 if N_vis < 0 else max(test_dataset.all_rays.shape[0] // N_vis,1)\n    idxs = list(range(0, test_dataset.all_rays.shape[0], img_eval_interval))\n    for idx, samples in tqdm(enumerate(test_dataset.all_rays[0::img_eval_interval]), file=sys.stdout):\n\n        W, H = test_dataset.img_wh\n        rays = samples.view(-1,samples.shape[-1])\n\n        rgb_map, _, depth_map, _, _ = renderer(rays, tensorf, chunk=4096, N_samples=N_samples,\n                                        ndc_ray=ndc_ray, white_bg = white_bg, device=device)\n        rgb_map = rgb_map.clamp(0.0, 1.0)\n\n        rgb_map, depth_map = rgb_map.reshape(H, W, 3).cpu(), depth_map.reshape(H, W).cpu()\n\n        depth_map, _ = visualize_depth_numpy(depth_map.numpy(),near_far)\n        if len(test_dataset.all_rgbs):\n            gt_rgb = test_dataset.all_rgbs[idxs[idx]].view(H, W, 3)\n            loss = torch.mean((rgb_map - gt_rgb) ** 2)\n            PSNRs.append(-10.0 * np.log(loss.item()) / np.log(10.0))\n\n            if compute_extra_metrics:\n                ssim = rgb_ssim(rgb_map, gt_rgb, 1)\n                l_a = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'alex', tensorf.device)\n                l_v = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'vgg', tensorf.device)\n                ssims.append(ssim)\n                l_alex.append(l_a)\n                l_vgg.append(l_v)\n\n        rgb_map = (rgb_map.numpy() * 255).astype('uint8')\n        # rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n        rgb_maps.append(rgb_map)\n        depth_maps.append(depth_map)\n        if savePath is not None:\n            imageio.imwrite(f'{savePath}/{prtx}{idx:03d}.png', rgb_map)\n            rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n            imageio.imwrite(f'{savePath}/rgbd/{prtx}{idx:03d}.png', rgb_map)\n\n    imageio.mimwrite(f'{savePath}/{prtx}video.mp4', np.stack(rgb_maps), fps=30, quality=10)\n    imageio.mimwrite(f'{savePath}/{prtx}depthvideo.mp4', np.stack(depth_maps), fps=30, quality=10)\n\n    if PSNRs:\n        psnr = np.mean(np.asarray(PSNRs))\n        if compute_extra_metrics:\n            ssim = np.mean(np.asarray(ssims))\n            l_a = np.mean(np.asarray(l_alex))\n            l_v = np.mean(np.asarray(l_vgg))\n            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr, ssim, l_a, l_v]))\n        else:\n            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr]))\n    return PSNRs\n\n\nclass TensoRFGoogleScannedTrainer:\n    def __init__(self, args: DictConfig):\n        super().__init__()\n        self.args = args\n        self.device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n        self.renderer = TensoRFRenderer()\n\n        if args.add_timestamp:\n            self.logfolder = f'{args.basedir}/{args.expname}{datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")}'\n        else:\n            self.logfolder = f'{args.basedir}/{args.expname}'\n\n        os.makedirs(self.logfolder, exist_ok=True)\n        self.model_log_file = os.path.join(self.logfolder, 'model_parameters.txt')\n\n    def save_model_details(self, model, description):\n        with open(self.model_log_file, 'a') as f:\n            f.write(f\"== {description} ==\\n\")\n            # Save necessary model details\n            f.write(f\"AABB: {model.aabb}\\n\")\n            # Add more model details as needed\n            f.write(\"\\n\")\n        count_parameters(model, self.model_log_file)\n\n    def train(self):\n        args = self.args\n        device = self.device\n        renderer = self.renderer\n\n        # init dataset\n        train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=False)\n        test_dataset = eval(args.data_loader)(args.datadir, split='test', downsample=args.downsample_train, is_stack=True)\n        white_bg = train_dataset.white_bg\n        near_far = train_dataset.near_far\n        ndc_ray = args.ndc_ray\n\n        # init resolution\n        upsamp_list = args.upsamp_list\n        update_AlphaMask_list = args.update_AlphaMask_list\n        n_lamb_sigma = args.n_lamb_sigma\n        n_lamb_sh = args.n_lamb_sh\n\n        summary_writer = SummaryWriter(self.logfolder)\n\n        # init parameters\n        aabb = train_dataset.scene_bbox.to(device)\n        reso_cur = N_to_reso(args.N_voxel_init, aabb)\n        nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n\n        if args.ckpt is not None and os.path.exists(args.ckpt):\n            ckpt = torch.load(args.ckpt, map_location=device)\n            kwargs = ckpt['kwargs']\n            kwargs.update({'device': device})\n            tensorf = eval(args.model_name)(**kwargs)\n            tensorf.load(ckpt)\n        else:\n            tensorf = eval(args.model_name)(aabb, reso_cur, device,\n                                            density_n_comp=n_lamb_sigma, appearance_n_comp=n_lamb_sh,\n                                            density_pick_plane=args.density_pick_plane, app_pick_plane=args.app_pick_plane,\n                                            app_dim=args.data_dim_color, near_far=near_far,\n                                            shadingMode=args.shadingMode, alphaMask_thres=args.alpha_mask_thre,\n                                            density_shift=args.density_shift, distance_scale=args.distance_scale,\n                                            pos_pe=args.pos_pe, view_pe=args.view_pe, fea_pe=args.fea_pe,\n                                            featureC=args.featureC, step_ratio=args.step_ratio,\n                                            fea2denseAct=args.fea2denseAct)\n\n        # Save model details at initialization\n        self.save_model_details(tensorf, 'Model Initialization')\n\n        grad_vars = tensorf.get_optparam_groups(args.lr_init, args.lr_basis)\n        if args.lr_decay_iters > 0:\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.lr_decay_iters)\n        else:\n            args.lr_decay_iters = args.n_iters\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.n_iters)\n\n        print(\"lr decay\", args.lr_decay_target_ratio, args.lr_decay_iters)\n\n        optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n        # linear in log space\n        N_voxel_list = (torch.round(torch.exp(torch.linspace(np.log(args.N_voxel_init), np.log(args.N_voxel_final),\n                                                             len(upsamp_list) + 1))).long()).tolist()[1:]\n\n        torch.cuda.empty_cache()\n        PSNRs, PSNRs_test = [], [0]\n\n        allrays, allrgbs = train_dataset.all_rays, train_dataset.all_rgbs\n        if not args.ndc_ray:\n            allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs, bbox_only=True)\n        trainingSampler = SimpleSampler(allrays.shape[0], args.batch_size)\n\n        Ortho_reg_weight = args.Ortho_weight\n        print(\"initial Ortho_reg_weight\", Ortho_reg_weight)\n\n        L1_reg_weight = args.L1_weight_inital\n        print(\"initial L1_reg_weight\", L1_reg_weight)\n        TV_weight_density, TV_weight_app = args.TV_weight_density, args.TV_weight_app\n        tvreg = TVLoss()\n        print(f\"initial TV_weight density: {TV_weight_density} appearance: {TV_weight_app}\")\n\n        pbar = tqdm(range(args.n_iters), miniters=args.progress_refresh_rate, file=sys.stdout)\n        for _ in pbar:\n\n            iteration = tensorf.iteration\n\n            ray_idx = trainingSampler.nextids()\n            rays_train, rgb_train = allrays[ray_idx], allrgbs[ray_idx].to(device)\n\n            # rgb_map, alphas_map, depth_map, weights, uncertainty\n            rgb_map, alphas_map, depth_map, weights, uncertainty = renderer(rays_train, tensorf,\n                                                                            chunk=args.batch_size,\n                                                                            N_samples=nSamples, white_bg=white_bg,\n                                                                            ndc_ray=ndc_ray, device=device,\n                                                                            is_train=True)\n\n            loss = torch.mean((rgb_map - rgb_train) ** 2)\n\n            # loss\n            total_loss = loss\n            if Ortho_reg_weight > 0:\n                loss_reg = tensorf.vector_comp_diffs()\n                total_loss += Ortho_reg_weight * loss_reg\n                summary_writer.add_scalar('train/reg', loss_reg.detach().item(), global_step=iteration)\n            if L1_reg_weight > 0:\n                loss_reg_L1 = tensorf.density_L1()\n                total_loss += L1_reg_weight * loss_reg_L1\n                summary_writer.add_scalar('train/reg_l1', loss_reg_L1.detach().item(), global_step=iteration)\n\n            if TV_weight_density > 0:\n                TV_weight_density *= lr_factor\n                loss_tv = tensorf.TV_loss_density(tvreg) * TV_weight_density\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_density', loss_tv.detach().item(), global_step=iteration)\n            if TV_weight_app > 0:\n                TV_weight_app *= lr_factor\n                loss_tv = tensorf.TV_loss_app(tvreg) * TV_weight_app\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_app', loss_tv.detach().item(), global_step=iteration)\n\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n\n            loss = loss.detach().item()\n\n            PSNRs.append(-10.0 * np.log(loss) / np.log(10.0))\n            summary_writer.add_scalar('train/PSNR', PSNRs[-1], global_step=iteration)\n            summary_writer.add_scalar('train/mse', loss, global_step=iteration)\n\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = param_group['lr'] * lr_factor\n\n\n            if iteration % args.vis_every == args.vis_every - 1 and args.N_vis != 0:\n                PSNRs_test = evaluation(test_dataset, tensorf, args, renderer, f'{self.logfolder}/imgs_vis/',\n                                        N_vis=args.N_vis,\n                                        prtx=f'{iteration:06d}_', N_samples=nSamples, white_bg=white_bg,\n                                        ndc_ray=ndc_ray, compute_extra_metrics=False)\n                summary_writer.add_scalar('test/psnr', np.mean(PSNRs_test), global_step=iteration)\n\n            # Print the current values of the losses.\n            if iteration % args.progress_refresh_rate == 0 or iteration == args.n_iters - 1:\n                pbar.set_description(\n                    f'Iteration {iteration:05d}:'\n                    + f' train_psnr = {float(np.mean(PSNRs)):.2f}'\n                    + f' test_psnr = {float(np.mean(PSNRs_test)):.2f}'\n                    + f' mse = {loss:.6f}'\n                )\n                PSNRs = []\n\n            if iteration in update_AlphaMask_list:\n\n                if reso_cur[0] * reso_cur[1] * reso_cur[2] < args:  # update volume resolution\n                    reso_mask = reso_cur\n                new_aabb = tensorf.updateAlphaMask(tuple(reso_mask))\n                if iteration == update_AlphaMask_list[0]:\n                    tensorf.shrink(new_aabb)\n                    # tensorVM.alphaMask = None\n                    L1_reg_weight = args.L1_weight_rest\n                    print(\"continuing L1_reg_weight\", L1_reg_weight)\n\n                if not args.ndc_ray and iteration == update_AlphaMask_list[1]:\n                    # filter rays outside the bbox\n                    allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs)\n                    trainingSampler = SimpleSampler(allrgbs.shape[0], args.batch_size)\n\n            if iteration in upsamp_list:\n                n_voxels = N_voxel_list.pop(0)\n                reso_cur = N_to_reso(n_voxels, tensorf.aabb)\n                nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n                tensorf.upsample_volume_grid(reso_cur)\n\n                # Save model details during upsampling\n                self.save_model_details(tensorf, 'Model Upsampling')\n\n                if args.lr_upsample_reset:\n                    print(\"reset lr to initial\")\n                    lr_scale = 1  # 0.1 ** (iteration / args.n_iters)\n                else:\n                    lr_scale = args.lr_decay_target_ratio ** (iteration / args.n_iters)\n                grad_vars = tensorf.get_optparam_groups(args.lr_init * lr_scale, args.lr_basis * lr_scale)\n                optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n            tensorf.iteration += 1\n\n        if args.render_train:\n            os.makedirs(f'{self.logfolder}/imgs_train_all', exist_ok=True)\n            train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=True)\n            PSNRs_test = evaluation(train_dataset,tensorf, args, renderer, f'{self.logfolder}/imgs_train_all/',\n                                    N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device)\n            print(f'======> {args.expname} TRAIN all psnr: {np.mean(PSNRs_test)} <========================')\n\n        return"}, {"role": "assistant", "content": "To integrate MLflow tracking into the provided code, you need to include the MLflow library and use its logging functionalities at appropriate points in your code. MLflow will be useful for tracking parameters, metrics, and artifacts related to your machine learning experiment.\n\nHere's the modified code with MLflow tracking added:\n\n1. **Initialize MLflow at the start.**\n2. **Log parameters once at the beginning.**\n3. **Log metrics during training iterations.**\n4. **Log artifacts like images and model parameters.**\n\nHere's the complete modified code:\n\n```python\nfrom omegaconf import DictConfig, OmegaConf\nimport os\nfrom tqdm.auto import tqdm\n\nimport json, random\nfrom data.blender import BlenderDataset\nfrom data.google_scanned import GoogleScannedPreprocessed\nfrom data.llff import LLFFDataset\nimport torch.utils.data\nfrom torch.utils.data import DataLoader\nfrom model.extractor.tensorf import TensorVMSplit\nfrom model.renderer.tensorf import TensoRFRenderer\nimport datetime\nimport sys\nimport imageio\nimport torch\nfrom .tensorf_utils import *\n\nfrom prettytable import PrettyTable\nimport mlflow\n\n# Initialize MLflow\nmlflow.set_experiment(\"TensoRF Experiment\")\nmlflow.start_run()\n\ndef count_parameters(model, file_path=None):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad:\n            continue\n        params = parameter.numel()\n        table.add_row([name, params])\n        total_params += params\n    table.add_row([\"Total Trainable Params\", total_params])\n\n    print(table)\n\n    if file_path:\n        with open(file_path, 'a') as f:\n            f.write(str(table) + \"\\n\")\n            f.write(f\"Total Trainable Params: {total_params}\\n\\n\")\n\n    return total_params\n\nclass SimpleSampler:\n    def __init__(self, total, batch):\n        if batch is None:\n            raise ValueError(\"Batch size must be provided\")\n        self.total = total\n        self.batch = batch\n        self.curr = total\n        self.ids = None\n\n    def nextids(self):\n        self.curr += self.batch\n        if self.curr + self.batch > self.total:\n            self.ids = torch.LongTensor(np.random.permutation(self.total))\n            self.curr = 0\n        return self.ids[self.curr:self.curr+self.batch]\n\n\n@torch.no_grad()\ndef evaluation(test_dataset, tensorf, args, renderer, savePath=None, N_vis=5, prtx='', N_samples=-1,\n               white_bg=False, ndc_ray=False, compute_extra_metrics=True, device='cuda'):\n    PSNRs, rgb_maps, depth_maps = [], [], []\n    ssims, l_alex, l_vgg = [], [], []\n    os.makedirs(savePath, exist_ok=True)\n    os.makedirs(savePath + \"/rgbd\", exist_ok=True)\n\n    try:\n        tqdm._instances.clear()\n    except Exception:\n        pass\n\n    near_far = test_dataset.near_far\n    img_eval_interval = 1 if N_vis < 0 else max(test_dataset.all_rays.shape[0] // N_vis, 1)\n    idxs = list(range(0, test_dataset.all_rays.shape[0], img_eval_interval))\n    for idx, samples in tqdm(enumerate(test_dataset.all_rays[0::img_eval_interval]), file=sys.stdout):\n\n        W, H = test_dataset.img_wh\n        rays = samples.view(-1, samples.shape[-1])\n\n        rgb_map, _, depth_map, _, _ = renderer(rays, tensorf, chunk=4096, N_samples=N_samples,\n                                               ndc_ray=ndc_ray, white_bg=white_bg, device=device)\n        rgb_map = rgb_map.clamp(0.0, 1.0)\n\n        rgb_map, depth_map = rgb_map.reshape(H, W, 3).cpu(), depth_map.reshape(H, W).cpu()\n\n        depth_map, _ = visualize_depth_numpy(depth_map.numpy(), near_far)\n        if len(test_dataset.all_rgbs):\n            gt_rgb = test_dataset.all_rgbs[idxs[idx]].view(H, W, 3)\n            loss = torch.mean((rgb_map - gt_rgb) ** 2)\n            PSNRs.append(-10.0 * np.log(loss.item()) / np.log(10.0))\n\n            if compute_extra_metrics:\n                ssim = rgb_ssim(rgb_map, gt_rgb, 1)\n                l_a = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'alex', tensorf.device)\n                l_v = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'vgg', tensorf.device)\n                ssims.append(ssim)\n                l_alex.append(l_a)\n                l_vgg.append(l_v)\n\n        rgb_map = (rgb_map.numpy() * 255).astype('uint8')\n        # rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n        rgb_maps.append(rgb_map)\n        depth_maps.append(depth_map)\n        if savePath is not None:\n            imageio.imwrite(f'{savePath}/{prtx}{idx:03d}.png', rgb_map)\n            rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n            imageio.imwrite(f'{savePath}/rgbd/{prtx}{idx:03d}.png', rgb_map)\n\n    imageio.mimwrite(f'{savePath}/{prtx}video.mp4', np.stack(rgb_maps), fps=30, quality=10)\n    imageio.mimwrite(f'{savePath}/{prtx}depthvideo.mp4', np.stack(depth_maps), fps=30, quality=10)\n\n    if PSNRs:\n        psnr = np.mean(np.asarray(PSNRs))\n        if compute_extra_metrics:\n            ssim = np.mean(np.asarray(ssims))\n            l_a = np.mean(np.asarray(l_alex))\n            l_v = np.mean(np.asarray(l_vgg))\n            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr, ssim, l_a, l_v]))\n        else:\n            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr]))\n    return PSNRs\n\n\nclass TensoRFGoogleScannedTrainer:\n    def __init__(self, args: DictConfig):\n        super().__init__()\n        self.args = args\n        self.device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n        self.renderer = TensoRFRenderer()\n\n        if args.add_timestamp:\n            self.logfolder = f'{args.basedir}/{args.expname}{datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")}'\n        else:\n            self.logfolder = f'{args.basedir}/{args.expname}'\n\n        os.makedirs(self.logfolder, exist_ok=True)\n        self.model_log_file = os.path.join(self.logfolder, 'model_parameters.txt')\n\n        # Log parameters to MLflow\n        mlflow.log_params(vars(args))\n\n    def save_model_details(self, model, description):\n        with open(self.model_log_file, 'a') as f:\n            f.write(f\"== {description} ==\\n\")\n            # Save necessary model details\n            f.write(f\"AABB: {model.aabb}\\n\")\n            # Add more model details as needed\n            f.write(\"\\n\")\n        count_parameters(model, self.model_log_file)\n        # Log model details as an artifact to MLflow\n        mlflow.log_artifact(self.model_log_file)\n\n    def train(self):\n        args = self.args\n        device = self.device\n        renderer = self.renderer\n\n        # init dataset\n        train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=False)\n        test_dataset = eval(args.data_loader)(args.datadir, split='test', downsample=args.downsample_train, is_stack=True)\n        white_bg = train_dataset.white_bg\n        near_far = train_dataset.near_far\n        ndc_ray = args.ndc_ray\n\n        # init resolution\n        upsamp_list = args.upsamp_list\n        update_AlphaMask_list = args.update_AlphaMask_list\n        n_lamb_sigma = args.n_lamb_sigma\n        n_lamb_sh = args.n_lamb_sh\n\n        summary_writer = SummaryWriter(self.logfolder)\n\n        # init parameters\n        aabb = train_dataset.scene_bbox.to(device)\n        reso_cur = N_to_reso(args.N_voxel_init, aabb)\n        nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n\n        if args.ckpt is not None and os.path.exists(args.ckpt):\n            ckpt = torch.load(args.ckpt, map_location=device)\n            kwargs = ckpt['kwargs']\n            kwargs.update({'device': device})\n            tensorf = eval(args.model_name)(**kwargs)\n            tensorf.load(ckpt)\n        else:\n            tensorf = eval(args.model_name)(aabb, reso_cur, device,\n                                            density_n_comp=n_lamb_sigma, appearance_n_comp=n_lamb_sh,\n                                            density_pick_plane=args.density_pick_plane, app_pick_plane=args.app_pick_plane,\n                                            app_dim=args.data_dim_color, near_far=near_far,\n                                            shadingMode=args.shadingMode, alphaMask_thres=args.alpha_mask_thre,\n                                            density_shift=args.density_shift, distance_scale=args.distance_scale,\n                                            pos_pe=args.pos_pe, view_pe=args.view_pe, fea_pe=args.fea_pe,\n                                            featureC=args.featureC, step_ratio=args.step_ratio,\n                                            fea2denseAct=args.fea2denseAct)\n\n        # Save model details at initialization\n        self.save_model_details(tensorf, 'Model Initialization')\n\n        grad_vars = tensorf.get_optparam_groups(args.lr_init, args.lr_basis)\n        if args.lr_decay_iters > 0:\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.lr_decay_iters)\n        else:\n            args.lr_decay_iters = args.n_iters\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.n_iters)\n\n        print(\"lr decay\", args.lr_decay_target_ratio, args.lr_decay_iters)\n\n        optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n        # linear in log space\n        N_voxel_list = (torch.round(torch.exp(torch.linspace(np.log(args.N_voxel_init), np.log(args.N_voxel_final),\n                                                             len(upsamp_list) + 1))).long()).tolist()[1:]\n\n        torch.cuda.empty_cache()\n        PSNRs, PSNRs_test = [], [0]\n\n        allrays, allrgbs = train_dataset.all_rays, train_dataset.all_rgbs\n        if not args.ndc_ray:\n            allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs, bbox_only=True)\n        trainingSampler = SimpleSampler(allrays.shape[0], args.batch_size)\n\n        Ortho_reg_weight = args.Ortho_weight\n        print(\"initial Ortho_reg_weight\", Ortho_reg_weight)\n\n        L1_reg_weight = args.L1_weight_inital\n        print(\"initial L1_reg_weight\", L1_reg_weight)\n        TV_weight_density, TV_weight_app = args.TV_weight_density, args.TV_weight_app\n        tvreg = TVLoss()\n        print(f\"initial TV_weight density: {TV_weight_density} appearance: {TV_weight_app}\")\n\n        pbar = tqdm(range(args.n_iters), miniters=args.progress_refresh_rate, file=sys.stdout)\n        for _ in pbar:\n\n            iteration = tensorf.iteration\n\n            ray_idx = trainingSampler.nextids()\n            rays_train, rgb_train = allrays[ray_idx], allrgbs[ray_idx].to(device)\n\n            # rgb_map, alphas_map, depth_map, weights, uncertainty\n            rgb_map, alphas_map, depth_map, weights, uncertainty = renderer(rays_train, tensorf,\n                                                                            chunk=args.batch_size,\n                                                                            N_samples=nSamples, white_bg=white_bg,\n                                                                            ndc_ray=ndc_ray, device=device,\n                                                                            is_train=True)\n\n            loss = torch.mean((rgb_map - rgb_train) ** 2)\n\n            # loss\n            total_loss = loss\n            if Ortho_reg_weight > 0:\n                loss_reg = tensorf.vector_comp_diffs()\n                total_loss += Ortho_reg_weight * loss_reg\n                summary_writer.add_scalar('train/reg', loss_reg.detach().item(), global_step=iteration)\n            if L1_reg_weight > 0:\n                loss_reg_L1 = tensorf.density_L1()\n                total_loss += L1_reg_weight * loss_reg_L1\n                summary_writer.add_scalar('train/reg_l1', loss_reg_L1.detach().item(), global_step=iteration)\n\n            if TV_weight_density > 0:\n                TV_weight_density *= lr_factor\n                loss_tv = tensorf.TV_loss_density(tvreg) * TV_weight_density\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_density', loss_tv.detach().item(), global_step=iteration)\n            if TV_weight_app > 0:\n                TV_weight_app *= lr_factor\n                loss_tv = tensorf.TV_loss_app(tvreg) * TV_weight_app\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_app', loss_tv.detach().item(), global_step=iteration)\n\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n\n            loss = loss.detach().item()\n\n            psnr_value = -10.0 * np.log(loss) / np.log(10.0)\n            PSNRs.append(psnr_value)\n            summary_writer.add_scalar('train/PSNR', PSNRs[-1], global_step=iteration)\n            summary_writer.add_scalar('train/mse', loss, global_step=iteration)\n\n            # Log metrics to MLflow\n            mlflow.log_metric('train/PSNR', psnr_value, step=iteration)\n            mlflow.log_metric('train/mse', loss, step=iteration)\n\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = param_group['lr'] * lr_factor\n\n\n            if iteration % args.vis_every == args.vis_every - 1 and args.N_vis != 0:\n                PSNRs_test = evaluation(test_dataset, tensorf, args, renderer, f'{self.logfolder}/imgs_vis/',\n                                        N_vis=args.N_vis,\n                                        prtx=f'{iteration:06d}_', N_samples=nSamples, white_bg=white_bg,\n                                        ndc_ray=ndc_ray, compute_extra_metrics=False)\n                mean_psnr_test = np.mean(PSNRs_test)\n                summary_writer.add_scalar('test/psnr', mean_psnr_test, global_step=iteration)\n\n                # Log test PSNR to MLflow\n                mlflow.log_metric('test/psnr', mean_psnr_test, step=iteration)\n\n            # Print the current values of the losses.\n            if iteration % args.progress_refresh_rate == 0 or iteration == args.n_iters - 1:\n                mean_psnr_train = float(np.mean(PSNRs))\n                mean_psnr_test = float(np.mean(PSNRs_test))\n                pbar.set_description(\n                    f'Iteration {iteration:05d}:'\n                    + f' train_psnr = {mean_psnr_train:.2f}'\n                    + f' test_psnr = {mean_psnr_test:.2f}'\n                    + f' mse = {loss:.6f}'\n                )\n                PSNRs = []\n\n            if iteration in update_AlphaMask_list:\n\n                if reso_cur[0] * reso_cur[1] * reso_cur[2] < args:  # update volume resolution\n                    reso_mask = reso_cur\n                new_aabb = tensorf.updateAlphaMask(tuple(reso_mask))\n                if iteration == update_AlphaMask_list[0]:\n                    tensorf.shrink(new_aabb)\n                    # tensorVM.alphaMask = None\n                    L1_reg_weight = args.L1_weight_rest\n                    print(\"continuing L1_reg_weight\", L1_reg_weight)\n\n                if not args.ndc_ray and iteration == update_AlphaMask_list[1]:\n                    # filter rays outside the bbox\n                    allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs)\n                    trainingSampler = SimpleSampler(allrgbs.shape[0], args.batch_size)\n\n            if iteration in upsamp_list:\n                n_voxels = N_voxel_list.pop(0)\n                reso_cur = N_to_reso(n_voxels, tensorf.aabb)\n                nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n                tensorf.upsample_volume_grid(reso_cur)\n\n                # Save model details during upsampling\n                self.save_model_details(tensorf, 'Model Upsampling')\n\n                if args.lr_upsample_reset:\n                    print(\"reset lr to initial\")\n                    lr_scale = 1  # 0.1 ** (iteration / args.n_iters)\n                else:\n                    lr_scale = args.lr_decay_target_ratio ** (iteration / args.n_iters)\n                grad_vars = tensorf.get_optparam_groups(args.lr_init * lr_scale, args.lr_basis * lr_scale)\n                optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n            tensorf.iteration += 1\n\n        if args.render_train:\n            os.makedirs(f'{self.logfolder}/imgs_train_all', exist_ok=True)\n            train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=True)\n            PSNRs_test = evaluation(train_dataset, tensorf, args, renderer, f'{self.logfolder}/imgs_train_all/',\n                                    N_vis=-1, N_samples=-1, white_bg=white_bg, ndc_ray=ndc_ray, device=device)\n            print(f'======> {args.expname} TRAIN all psnr: {np.mean(PSNRs_test)} <========================')\n\n        # End MLflow run\n        mlflow.end_run()\n\n        return\n```\n\n### Summary of Changes:\n1. **Imports:** Import MLflow.\n2. **Initialization:** Start an MLflow run at the beginning of the script.\n3. **Logging Parameters:** Log experiment parameters to MLflow when initializing the `TensoRFGoogleScannedTrainer`.\n4. **Logging Metrics:** Log training and testing PSNR and MSE metrics within the training loop.\n5. **Logging Artifacts:** Save and log model details as artifacts.\n\nWith the above changes, the training process can be tracked and analyzed through the MLflow UI. You can visualize metrics, parameters, and artifacts to better understand the model's performance and experiment variations."}, {"role": "user", "content": "Add MLflow to this so i can track the experiments. Also I want to load the name of the experiments from args.expname\n\nfrom omegaconf import DictConfig, OmegaConf\nimport os\nfrom tqdm.auto import tqdm\n\nimport json, random\nfrom data.blender import BlenderDataset\nfrom data.google_scanned import GoogleScannedPreprocessed\nfrom data.llff import LLFFDataset\nimport torch.utils.data\nfrom torch.utils.data import DataLoader\nfrom model.extractor.tensorf import TensorVMSplit\nfrom model.renderer.tensorf import TensoRFRenderer\nfrom tensorboardX import SummaryWriter\nimport datetime\nimport sys\nimport imageio\nimport torch\nfrom .tensorf_utils import *\n\nfrom prettytable import PrettyTable\n\ndef count_parameters(model, file_path=None):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad:\n            continue\n        params = parameter.numel()\n        table.add_row([name, params])\n        total_params += params\n    table.add_row([\"Total Trainable Params\", total_params])\n\n    print(table)\n\n    if file_path:\n        with open(file_path, 'a') as f:\n            f.write(str(table) + \"\\n\")\n            f.write(f\"Total Trainable Params: {total_params}\\n\\n\")\n\n    return total_params\n\nclass SimpleSampler:\n    def __init__(self, total, batch):\n        if batch is None:\n            raise ValueError(\"Batch size must be provided\")\n        self.total = total\n        self.batch = batch\n        self.curr = total\n        self.ids = None\n\n    def nextids(self):\n        self.curr += self.batch\n        if self.curr + self.batch > self.total:\n            self.ids = torch.LongTensor(np.random.permutation(self.total))\n            self.curr = 0\n        return self.ids[self.curr:self.curr+self.batch]\n\n\n@torch.no_grad()\ndef evaluation(test_dataset,tensorf, args, renderer, savePath=None, N_vis=5, prtx='', N_samples=-1,\n               white_bg=False, ndc_ray=False, compute_extra_metrics=True, device='cuda'):\n    PSNRs, rgb_maps, depth_maps = [], [], []\n    ssims,l_alex,l_vgg=[],[],[]\n    os.makedirs(savePath, exist_ok=True)\n    os.makedirs(savePath+\"/rgbd\", exist_ok=True)\n\n    try:\n        tqdm._instances.clear()\n    except Exception:\n        pass\n\n    near_far = test_dataset.near_far\n    img_eval_interval = 1 if N_vis < 0 else max(test_dataset.all_rays.shape[0] // N_vis,1)\n    idxs = list(range(0, test_dataset.all_rays.shape[0], img_eval_interval))\n    for idx, samples in tqdm(enumerate(test_dataset.all_rays[0::img_eval_interval]), file=sys.stdout):\n\n        W, H = test_dataset.img_wh\n        rays = samples.view(-1,samples.shape[-1])\n\n        rgb_map, _, depth_map, _, _ = renderer(rays, tensorf, chunk=4096, N_samples=N_samples,\n                                        ndc_ray=ndc_ray, white_bg = white_bg, device=device)\n        rgb_map = rgb_map.clamp(0.0, 1.0)\n\n        rgb_map, depth_map = rgb_map.reshape(H, W, 3).cpu(), depth_map.reshape(H, W).cpu()\n\n        depth_map, _ = visualize_depth_numpy(depth_map.numpy(),near_far)\n        if len(test_dataset.all_rgbs):\n            gt_rgb = test_dataset.all_rgbs[idxs[idx]].view(H, W, 3)\n            loss = torch.mean((rgb_map - gt_rgb) ** 2)\n            PSNRs.append(-10.0 * np.log(loss.item()) / np.log(10.0))\n\n            if compute_extra_metrics:\n                ssim = rgb_ssim(rgb_map, gt_rgb, 1)\n                l_a = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'alex', tensorf.device)\n                l_v = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'vgg', tensorf.device)\n                ssims.append(ssim)\n                l_alex.append(l_a)\n                l_vgg.append(l_v)\n\n        rgb_map = (rgb_map.numpy() * 255).astype('uint8')\n        # rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n        rgb_maps.append(rgb_map)\n        depth_maps.append(depth_map)\n        if savePath is not None:\n            imageio.imwrite(f'{savePath}/{prtx}{idx:03d}.png', rgb_map)\n            rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n            imageio.imwrite(f'{savePath}/rgbd/{prtx}{idx:03d}.png', rgb_map)\n\n    imageio.mimwrite(f'{savePath}/{prtx}video.mp4', np.stack(rgb_maps), fps=30, quality=10)\n    imageio.mimwrite(f'{savePath}/{prtx}depthvideo.mp4', np.stack(depth_maps), fps=30, quality=10)\n\n    if PSNRs:\n        psnr = np.mean(np.asarray(PSNRs))\n        if compute_extra_metrics:\n            ssim = np.mean(np.asarray(ssims))\n            l_a = np.mean(np.asarray(l_alex))\n            l_v = np.mean(np.asarray(l_vgg))\n            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr, ssim, l_a, l_v]))\n        else:\n            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr]))\n    return PSNRs\n\n\nclass TensoRFGoogleScannedTrainer:\n    def __init__(self, args: DictConfig):\n        super().__init__()\n        self.args = args\n        self.device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n        self.renderer = TensoRFRenderer()\n\n        if args.add_timestamp:\n            self.logfolder = f'{args.basedir}/{args.expname}{datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")}'\n        else:\n            self.logfolder = f'{args.basedir}/{args.expname}'\n\n        os.makedirs(self.logfolder, exist_ok=True)\n        self.model_log_file = os.path.join(self.logfolder, 'model_parameters.txt')\n\n    def save_model_details(self, model, description):\n        with open(self.model_log_file, 'a') as f:\n            f.write(f\"== {description} ==\\n\")\n            # Save necessary model details\n            f.write(f\"AABB: {model.aabb}\\n\")\n            # Add more model details as needed\n            f.write(\"\\n\")\n        count_parameters(model, self.model_log_file)\n\n    def train(self):\n        args = self.args\n        device = self.device\n        renderer = self.renderer\n\n        # init dataset\n        train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=False)\n        test_dataset = eval(args.data_loader)(args.datadir, split='test', downsample=args.downsample_train, is_stack=True)\n        white_bg = train_dataset.white_bg\n        near_far = train_dataset.near_far\n        ndc_ray = args.ndc_ray\n\n        # init resolution\n        upsamp_list = args.upsamp_list\n        update_AlphaMask_list = args.update_AlphaMask_list\n        n_lamb_sigma = args.n_lamb_sigma\n        n_lamb_sh = args.n_lamb_sh\n\n        summary_writer = SummaryWriter(self.logfolder)\n\n        # init parameters\n        aabb = train_dataset.scene_bbox.to(device)\n        reso_cur = N_to_reso(args.N_voxel_init, aabb)\n        nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n\n        if args.ckpt is not None and os.path.exists(args.ckpt):\n            ckpt = torch.load(args.ckpt, map_location=device)\n            kwargs = ckpt['kwargs']\n            kwargs.update({'device': device})\n            tensorf = eval(args.model_name)(**kwargs)\n            tensorf.load(ckpt)\n        else:\n            tensorf = eval(args.model_name)(aabb, reso_cur, device,\n                                            density_n_comp=n_lamb_sigma, appearance_n_comp=n_lamb_sh,\n                                            density_pick_plane=args.density_pick_plane, app_pick_plane=args.app_pick_plane,\n                                            app_dim=args.data_dim_color, near_far=near_far,\n                                            shadingMode=args.shadingMode, alphaMask_thres=args.alpha_mask_thre,\n                                            density_shift=args.density_shift, distance_scale=args.distance_scale,\n                                            pos_pe=args.pos_pe, view_pe=args.view_pe, fea_pe=args.fea_pe,\n                                            featureC=args.featureC, step_ratio=args.step_ratio,\n                                            fea2denseAct=args.fea2denseAct)\n\n        # Save model details at initialization\n        self.save_model_details(tensorf, 'Model Initialization')\n\n        grad_vars = tensorf.get_optparam_groups(args.lr_init, args.lr_basis)\n        if args.lr_decay_iters > 0:\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.lr_decay_iters)\n        else:\n            args.lr_decay_iters = args.n_iters\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.n_iters)\n\n        print(\"lr decay\", args.lr_decay_target_ratio, args.lr_decay_iters)\n\n        optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n        # linear in log space\n        N_voxel_list = (torch.round(torch.exp(torch.linspace(np.log(args.N_voxel_init), np.log(args.N_voxel_final),\n                                                             len(upsamp_list) + 1))).long()).tolist()[1:]\n\n        torch.cuda.empty_cache()\n        PSNRs, PSNRs_test = [], [0]\n\n        allrays, allrgbs = train_dataset.all_rays, train_dataset.all_rgbs\n        if not args.ndc_ray:\n            allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs, bbox_only=True)\n        trainingSampler = SimpleSampler(allrays.shape[0], args.batch_size)\n\n        Ortho_reg_weight = args.Ortho_weight\n        print(\"initial Ortho_reg_weight\", Ortho_reg_weight)\n\n        L1_reg_weight = args.L1_weight_inital\n        print(\"initial L1_reg_weight\", L1_reg_weight)\n        TV_weight_density, TV_weight_app = args.TV_weight_density, args.TV_weight_app\n        tvreg = TVLoss()\n        print(f\"initial TV_weight density: {TV_weight_density} appearance: {TV_weight_app}\")\n\n        pbar = tqdm(range(args.n_iters), miniters=args.progress_refresh_rate, file=sys.stdout)\n        for _ in pbar:\n\n            iteration = tensorf.iteration\n\n            ray_idx = trainingSampler.nextids()\n            rays_train, rgb_train = allrays[ray_idx], allrgbs[ray_idx].to(device)\n\n            # rgb_map, alphas_map, depth_map, weights, uncertainty\n            rgb_map, alphas_map, depth_map, weights, uncertainty = renderer(rays_train, tensorf,\n                                                                            chunk=args.batch_size,\n                                                                            N_samples=nSamples, white_bg=white_bg,\n                                                                            ndc_ray=ndc_ray, device=device,\n                                                                            is_train=True)\n\n            loss = torch.mean((rgb_map - rgb_train) ** 2)\n\n            # loss\n            total_loss = loss\n            if Ortho_reg_weight > 0:\n                loss_reg = tensorf.vector_comp_diffs()\n                total_loss += Ortho_reg_weight * loss_reg\n                summary_writer.add_scalar('train/reg', loss_reg.detach().item(), global_step=iteration)\n            if L1_reg_weight > 0:\n                loss_reg_L1 = tensorf.density_L1()\n                total_loss += L1_reg_weight * loss_reg_L1\n                summary_writer.add_scalar('train/reg_l1', loss_reg_L1.detach().item(), global_step=iteration)\n\n            if TV_weight_density > 0:\n                TV_weight_density *= lr_factor\n                loss_tv = tensorf.TV_loss_density(tvreg) * TV_weight_density\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_density', loss_tv.detach().item(), global_step=iteration)\n            if TV_weight_app > 0:\n                TV_weight_app *= lr_factor\n                loss_tv = tensorf.TV_loss_app(tvreg) * TV_weight_app\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_app', loss_tv.detach().item(), global_step=iteration)\n\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n\n            loss = loss.detach().item()\n\n            PSNRs.append(-10.0 * np.log(loss) / np.log(10.0))\n            summary_writer.add_scalar('train/PSNR', PSNRs[-1], global_step=iteration)\n            summary_writer.add_scalar('train/mse', loss, global_step=iteration)\n\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = param_group['lr'] * lr_factor\n\n\n            if iteration % args.vis_every == args.vis_every - 1 and args.N_vis != 0:\n                PSNRs_test = evaluation(test_dataset, tensorf, args, renderer, f'{self.logfolder}/imgs_vis/',\n                                        N_vis=args.N_vis,\n                                        prtx=f'{iteration:06d}_', N_samples=nSamples, white_bg=white_bg,\n                                        ndc_ray=ndc_ray, compute_extra_metrics=False)\n                summary_writer.add_scalar('test/psnr', np.mean(PSNRs_test), global_step=iteration)\n\n            # Print the current values of the losses.\n            if iteration % args.progress_refresh_rate == 0 or iteration == args.n_iters - 1:\n                pbar.set_description(\n                    f'Iteration {iteration:05d}:'\n                    + f' train_psnr = {float(np.mean(PSNRs)):.2f}'\n                    + f' test_psnr = {float(np.mean(PSNRs_test)):.2f}'\n                    + f' mse = {loss:.6f}'\n                )\n                PSNRs = []\n\n            if iteration in update_AlphaMask_list:\n\n                if reso_cur[0] * reso_cur[1] * reso_cur[2] < args:  # update volume resolution\n                    reso_mask = reso_cur\n                new_aabb = tensorf.updateAlphaMask(tuple(reso_mask))\n                if iteration == update_AlphaMask_list[0]:\n                    tensorf.shrink(new_aabb)\n                    # tensorVM.alphaMask = None\n                    L1_reg_weight = args.L1_weight_rest\n                    print(\"continuing L1_reg_weight\", L1_reg_weight)\n\n                if not args.ndc_ray and iteration == update_AlphaMask_list[1]:\n                    # filter rays outside the bbox\n                    allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs)\n                    trainingSampler = SimpleSampler(allrgbs.shape[0], args.batch_size)\n\n            if iteration in upsamp_list:\n                n_voxels = N_voxel_list.pop(0)\n                reso_cur = N_to_reso(n_voxels, tensorf.aabb)\n                nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n                tensorf.upsample_volume_grid(reso_cur)\n\n                # Save model details during upsampling\n                self.save_model_details(tensorf, 'Model Upsampling')\n\n                if args.lr_upsample_reset:\n                    print(\"reset lr to initial\")\n                    lr_scale = 1  # 0.1 ** (iteration / args.n_iters)\n                else:\n                    lr_scale = args.lr_decay_target_ratio ** (iteration / args.n_iters)\n                grad_vars = tensorf.get_optparam_groups(args.lr_init * lr_scale, args.lr_basis * lr_scale)\n                optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n            tensorf.iteration += 1\n\n        if args.render_train:\n            os.makedirs(f'{self.logfolder}/imgs_train_all', exist_ok=True)\n            train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=True)\n            PSNRs_test = evaluation(train_dataset,tensorf, args, renderer, f'{self.logfolder}/imgs_train_all/',\n                                    N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device)\n            print(f'======> {args.expname} TRAIN all psnr: {np.mean(PSNRs_test)} <========================')\n\n        return"}, {"role": "assistant", "content": "To integrate MLflow for experiment tracking in your training script, we will make a few modifications, including importing `mlflow`, starting a MLflow experiment, logging parameters and metrics, and ensuring we log appropriately at the various stages of training and evaluation.\n\nHere\u2019s a modified version of your `TensoRFGoogleScannedTrainer` class incorporating MLflow tracking. Make sure MLflow is installed in your environment (`pip install mlflow`), and you'll need to set up a tracking server or run it locally to log your experiments.\n\nHere\u2019s how you can integrate MLflow into your existing code:\n\n```python\nfrom omegaconf import DictConfig, OmegaConf\nimport os\nfrom tqdm.auto import tqdm\nimport json, random\nfrom data.blender import BlenderDataset\nfrom data.google_scanned import GoogleScannedPreprocessed\nfrom data.llff import LLFFDataset\nimport torch.utils.data\nfrom torch.utils.data import DataLoader\nfrom model.extractor.tensorf import TensorVMSplit\nfrom model.renderer.tensorf import TensoRFRenderer\nfrom tensorboardX import SummaryWriter\nimport datetime\nimport sys\nimport imageio\nimport torch\nimport mlflow  # Import MLflow\nfrom .tensorf_utils import *\nfrom prettytable import PrettyTable\n\n# ... [rest of the code unchanged until the TensoRFGoogleScannedTrainer class]\n\nclass TensoRFGoogleScannedTrainer:\n    def __init__(self, args: DictConfig):\n        super().__init__()\n        self.args = args\n        self.device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n        self.renderer = TensoRFRenderer()\n\n        # Initializing MLflow\n        mlflow.set_experiment(args.expname)  # Set the experiment name from args.expname\n        self.mlflow_run = mlflow.start_run()  # Start an MLflow run\n\n        if args.add_timestamp:\n            self.logfolder = f'{args.basedir}/{args.expname}{datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")}'\n        else:\n            self.logfolder = f'{args.basedir}/{args.expname}'\n\n        os.makedirs(self.logfolder, exist_ok=True)\n        self.model_log_file = os.path.join(self.logfolder, 'model_parameters.txt')\n\n        # Log parameters\n        mlflow.log_params({\n            \"exp_name\": args.expname,\n            \"data_loader\": args.data_loader,\n            \"batch_size\": args.batch_size,\n            \"lr_init\": args.lr_init,\n            \"n_iters\": args.n_iters,\n            \"ndc_ray\": args.ndc_ray,\n            \"downsample_train\": args.downsample_train,\n            # Add more parameters as needed...\n        })\n\n    def save_model_details(self, model, description):\n        with open(self.model_log_file, 'a') as f:\n            f.write(f\"== {description} ==\\n\")\n            # Save necessary model details\n            f.write(f\"AABB: {model.aabb}\\n\")\n            # Add more model details as needed\n            f.write(\"\\n\")\n        count_parameters(model, self.model_log_file)\n\n    def train(self):\n        args = self.args\n        device = self.device\n        renderer = self.renderer\n\n        # init dataset\n        train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=False)\n        test_dataset = eval(args.data_loader)(args.datadir, split='test', downsample=args.downsample_train, is_stack=True)\n        white_bg = train_dataset.white_bg\n        near_far = train_dataset.near_far\n        ndc_ray = args.ndc_ray\n\n        # init resolution\n        upsamp_list = args.upsamp_list\n        update_AlphaMask_list = args.update_AlphaMask_list\n        n_lamb_sigma = args.n_lamb_sigma\n        n_lamb_sh = args.n_lamb_sh\n\n        summary_writer = SummaryWriter(self.logfolder)\n\n        # init parameters\n        aabb = train_dataset.scene_bbox.to(device)\n        reso_cur = N_to_reso(args.N_voxel_init, aabb)\n        nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n\n        if args.ckpt is not None and os.path.exists(args.ckpt):\n            ckpt = torch.load(args.ckpt, map_location=device)\n            kwargs = ckpt['kwargs']\n            kwargs.update({'device': device})\n            tensorf = eval(args.model_name)(**kwargs)\n            tensorf.load(ckpt)\n        else:\n            tensorf = eval(args.model_name)(aabb, reso_cur, device,\n                                            density_n_comp=n_lamb_sigma, appearance_n_comp=n_lamb_sh,\n                                            density_pick_plane=args.density_pick_plane, app_pick_plane=args.app_pick_plane,\n                                            app_dim=args.data_dim_color, near_far=near_far,\n                                            shadingMode=args.shadingMode, alphaMask_thres=args.alpha_mask_thre,\n                                            density_shift=args.density_shift, distance_scale=args.distance_scale,\n                                            pos_pe=args.pos_pe, view_pe=args.view_pe, fea_pe=args.fea_pe,\n                                            featureC=args.featureC, step_ratio=args.step_ratio,\n                                            fea2denseAct=args.fea2denseAct)\n\n        # Save model details at initialization\n        self.save_model_details(tensorf, 'Model Initialization')\n\n        grad_vars = tensorf.get_optparam_groups(args.lr_init, args.lr_basis)\n        if args.lr_decay_iters > 0:\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.lr_decay_iters)\n        else:\n            args.lr_decay_iters = args.n_iters\n            lr_factor = args.lr_decay_target_ratio ** (1 / args.n_iters)\n\n        optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n        # linear in log space\n        N_voxel_list = (torch.round(torch.exp(torch.linspace(np.log(args.N_voxel_init), np.log(args.N_voxel_final),\n                                                             len(upsamp_list) + 1))).long()).tolist()[1:]\n\n        torch.cuda.empty_cache()\n        PSNRs, PSNRs_test = [], [0]\n\n        allrays, allrgbs = train_dataset.all_rays, train_dataset.all_rgbs\n        if not args.ndc_ray:\n            allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs, bbox_only=True)\n        trainingSampler = SimpleSampler(allrays.shape[0], args.batch_size)\n\n        Ortho_reg_weight = args.Ortho_weight\n        L1_reg_weight = args.L1_weight_inital\n        TV_weight_density, TV_weight_app = args.TV_weight_density, args.TV_weight_app\n        tvreg = TVLoss()\n\n        pbar = tqdm(range(args.n_iters), miniters=args.progress_refresh_rate, file=sys.stdout)\n        for _ in pbar:\n\n            iteration = tensorf.iteration\n\n            ray_idx = trainingSampler.nextids()\n            rays_train, rgb_train = allrays[ray_idx], allrgbs[ray_idx].to(device)\n\n            rgb_map, alphas_map, depth_map, weights, uncertainty = renderer(rays_train, tensorf,\n                                                                            chunk=args.batch_size,\n                                                                            N_samples=nSamples, white_bg=white_bg,\n                                                                            ndc_ray=ndc_ray, device=device,\n                                                                            is_train=True)\n\n            loss = torch.mean((rgb_map - rgb_train) ** 2)\n\n            # loss\n            total_loss = loss\n            if Ortho_reg_weight > 0:\n                loss_reg = tensorf.vector_comp_diffs()\n                total_loss += Ortho_reg_weight * loss_reg\n                summary_writer.add_scalar('train/reg', loss_reg.detach().item(), global_step=iteration)\n            if L1_reg_weight > 0:\n                loss_reg_L1 = tensorf.density_L1()\n                total_loss += L1_reg_weight * loss_reg_L1\n                summary_writer.add_scalar('train/reg_l1', loss_reg_L1.detach().item(), global_step=iteration)\n\n            if TV_weight_density > 0:\n                TV_weight_density *= lr_factor\n                loss_tv = tensorf.TV_loss_density(tvreg) * TV_weight_density\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_density', loss_tv.detach().item(), global_step=iteration)\n            if TV_weight_app > 0:\n                TV_weight_app *= lr_factor\n                loss_tv = tensorf.TV_loss_app(tvreg) * TV_weight_app\n                total_loss = total_loss + loss_tv\n                summary_writer.add_scalar('train/reg_tv_app', loss_tv.detach().item(), global_step=iteration)\n\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n\n            loss = loss.detach().item()\n\n            PSNRs.append(-10.0 * np.log(loss) / np.log(10.0))\n            summary_writer.add_scalar('train/PSNR', PSNRs[-1], global_step=iteration)\n            summary_writer.add_scalar('train/mse', loss, global_step=iteration)\n\n            # Log loss and PSNR to MLflow\n            mlflow.log_metric(\"train/PSNR\", PSNRs[-1], step=iteration)\n            mlflow.log_metric(\"train/mse\", loss, step=iteration)\n\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = param_group['lr'] * lr_factor\n\n\n            if iteration % args.vis_every == args.vis_every - 1 and args.N_vis != 0:\n                PSNRs_test = evaluation(test_dataset, tensorf, args, renderer, f'{self.logfolder}/imgs_vis/',\n                                        N_vis=args.N_vis,\n                                        prtx=f'{iteration:06d}_', N_samples=nSamples, white_bg=white_bg,\n                                        ndc_ray=ndc_ray, compute_extra_metrics=False)\n                summary_writer.add_scalar('test/psnr', np.mean(PSNRs_test), global_step=iteration)\n\n                # Log test PSNR to MLflow\n                mlflow.log_metric(\"test/PSNR\", np.mean(PSNRs_test), step=iteration)\n\n            # Print the current values of the losses.\n            if iteration % args.progress_refresh_rate == 0 or iteration == args.n_iters - 1:\n                pbar.set_description(\n                    f'Iteration {iteration:05d}:'\n                    + f' train_psnr = {float(np.mean(PSNRs)):.2f}'\n                    + f' test_psnr = {float(np.mean(PSNRs_test)):.2f}'\n                    + f' mse = {loss:.6f}'\n                )\n                PSNRs = []\n\n            if iteration in update_AlphaMask_list:\n                if reso_cur[0] * reso_cur[1] * reso_cur[2] < args:  # update volume resolution\n                    reso_mask = reso_cur\n                new_aabb = tensorf.updateAlphaMask(tuple(reso_mask))\n                if iteration == update_AlphaMask_list[0]:\n                    tensorf.shrink(new_aabb)\n                    L1_reg_weight = args.L1_weight_rest\n\n                if not args.ndc_ray and iteration == update_AlphaMask_list[1]:\n                    # filter rays outside the bbox\n                    allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs)\n                    trainingSampler = SimpleSampler(allrgbs.shape[0], args.batch_size)\n\n            if iteration in upsamp_list:\n                n_voxels = N_voxel_list.pop(0)\n                reso_cur = N_to_reso(n_voxels, tensorf.aabb)\n                nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n                tensorf.upsample_volume_grid(reso_cur)\n\n                # Save model details during upsampling\n                self.save_model_details(tensorf, 'Model Upsampling')\n\n                if args.lr_upsample_reset:\n                    lr_scale = 1\n                else:\n                    lr_scale = args.lr_decay_target_ratio ** (iteration / args.n_iters)\n                grad_vars = tensorf.get_optparam_groups(args.lr_init * lr_scale, args.lr_basis * lr_scale)\n                optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n\n            tensorf.iteration += 1\n\n        if args.render_train:\n            os.makedirs(f'{self.logfolder}/imgs_train_all', exist_ok=True)\n            train_dataset = eval(args.data_loader)(args.datadir, split='train', downsample=args.downsample_train, is_stack=True)\n            PSNRs_test = evaluation(train_dataset,tensorf, args, renderer, f'{self.logfolder}/imgs_train_all/',\n                                    N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device)\n            print(f'======> {args.expname} TRAIN all psnr: {np.mean(PSNRs_test)} <========================')\n\n            # Log final training PSNR to MLflow\n            mlflow.log_metric(\"final/train/PSNR\", np.mean(PSNRs_test))\n\n        # End MLflow run\n        mlflow.end_run()\n\n        return\n```\n\n### Key Changes and Additions:\n\n1. **MLflow Import**: We import `mlflow` at the beginning of the script.\n\n2. **Experiment Setup**: Inside the `__init__` method, we set up the experiment name using `mlflow.set_experiment(args.expname)`, and start a new run with `mlflow.start_run()`.\n\n3. **Logging Parameters**: Log key parameters using `mlflow.log_params({ ... })` to keep track of the hyperparameters used in the run.\n\n4. **Logging Metrics**: Log metrics during training and evaluation using `mlflow.log_metric()` for the training and test PSNR and loss values.\n\n5. **Ending the Run**: End the MLflow run with `mlflow.end_run()` to ensure that results are properly recorded.\n\nMake sure to configure MLflow to point to your desired tracking server or set it up to log locally. This integration will help you effectively track the experiments, visualize metrics, and compare different runs."}]